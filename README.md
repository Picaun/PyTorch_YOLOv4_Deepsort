# YOLO_for_Pedestrian_Detection

## 前言  
目标检测是计算机视觉中的一个重要研究方向，它的目的是在图像或视频中定位和识别出感兴趣的物体。目标检测在许多领域有着广泛的应用，如安防监控、自动驾驶、医学影像分析等。目标检测算法可以分为两类：一类是基于区域提议的方法，如R-CNN系列；另一类是基于回归的方法，如YOLO系列。基于区域提议的方法通常需要两个阶段：首先生成候选区域，然后对每个区域进行分类和回归。这种方法虽然可以达到较高的精度，但是速度较慢，不适合实时应用。基于回归的方法则只需要一个阶段：直接从图像中预测出物体的类别和位置。这种方法具有速度快、简单易实现等优点，但是精度相对较低。
YOLO v4是一种基于回归的目标检测算法，它在2020年由Bochkovskiy等人提出，是YOLO v3算法的改进版。YOLO v4主要使用了一种新的CNN架构CSPNet来提高特征提取能力，并且引入了一种基于k-means聚类的方法来生成锚框。YOLO v4在COCO2017数据集上达到了45.5% mAP和65 FPS（mAP表示平均精度，FPS表示每秒处理帧数），表现出了优异的速度和精度。
YOLO v4算法是当前最先进的实时对象检测模型之一，在COCO数据集上取得了很高的平均精度 (AP) 和帧率精度 (FPS)。然而，YOLO v4算法也存在一些不足之处或可以改进之处。例如，在卷积计算量和模型参数量方面还有较大优化空间；在损失函数方面还可以考虑更多因素来提高检测精度；在多目标跟踪方面还需要结合其他算法来实现。
本毕业设计以YOLO v4算法为基础，在COCO2017行人数据集上进行测试，并对其进行改进优化。具体地说，在卷积层上使用深度分离卷积替换原始YOLO算法中使用到普通卷积层来降低计算量与参数量；在损失函数上通过对比使用GIoU、DIoU、CIoU作为损失函数对检测精度影响并选择合适损失函数；最后利用SORT算法实现行人跟踪功能。本毕业设计旨在提高YOLO v4算法在行人检测与跟踪任务上表现，并探索其在实际场景中应用潜力。

## 论文研究思路及工作方法  
* 总体目标和方法：本研究旨在利用YOLO v4算法，测试COCO2017行人数据集性能表现，并根据测试结果，对YOLO算法的检测速度和精度两个方面进行改进。本研究采用定量的研究范式，使用计算机视觉和深度学习的相关技术。  
* 研究设计类型：本研究选择实验设计作为研究设计类型，通过对比不同版本的YOLO算法在同一数据集上的检测效果，评估其优劣，并提出改进方案。  
* 总体群体和抽样方法：本研究使用COCO2017行人数据集作为总体群体，该数据集包含118287张训练图像和5000张验证图像，共有117266个行人实例。本研究使用全样本法，即将所有图像都用于训练或验证。  
* 数据收集方法：本研究使用YOLO v4算法作为数据收集方法，分别在COCO2017行人数据集上进行训练和验证，并记录其检测速度（FPS）和精度（mAP）等指标。  
* 数据收集程序：本研究遵循以下步骤进行数据收集：  
1、下载并安装YOLO v3和YOLO v4算法的源代码及依赖库；  
2、下载并解压COCO2017行人数据集，并将其转换为适合YOLO算法输入的格式；  
3、修改配置文件中的相关参数，如类别数、锚框尺寸、学习率、批量大小等；  
4、使用GPU加速运行训练脚本，并保存模型权重文件；  
5、使用GPU加速运行验证脚本，并输出检测结果及评估指标；  
6、根据测试结果，对YOLO算法进行改进：  
    - 使用深度分离卷积替换原始YOLO算法的普通卷积来降低卷积计算量和模型参数量；  
    - 对比使用GIoU、DIoU、CIoU作为损失函数对检测精度的影响，并设计出合适的损失函数；  
    - 利用SORT算法，在检测结果基础上实现行人跟踪。  
    - 对改进后的YOLO算法重复上述训练和验证过程，并与原始版本进行对比分析。  
* 数据分析策略：本研究使用统计分析软件（如Excel或SPSS）对收集到的数据进行处理和分析，主要包括以下内容：  
1、描述性统计分析：计算不同版本的YOLO算法在COCO2017行人数据集上的平均检测速度（FPS）和平均精度（mAP），并绘制相应的柱状图或折线图；  
2、推断性统计分析：使用t检验或ANOVA等方法比较不同版本的YOLO算法在COCO2017行人数据集上的检测速度和精度是否存在显著差异，并计算相应的p值；  
3、结果解释和讨论：根据数据分析结果，解释并讨论YOLO算法的优缺点，以及改进方案的有效性和局限性，同时结合相关文献进行对比和支持；  
* 结论和建议：总结本研究的主要发现和贡献，指出本研究的局限性和不足，以及提出未来研究的方向和建议。  